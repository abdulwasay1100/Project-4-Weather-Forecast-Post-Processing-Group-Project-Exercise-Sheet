{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Project 4: \"Weather Forecast Post-Processing\": Group Project Exercise Sheet\n",
    "\n",
    "Group N: Jane Doe, John Doe, James Doe **<- Enter your group number / name here**\n",
    "\n",
    "Welcome to the lovely home of your group project for this years' *Introduction to Advanced Data Analytics* Lecture. This is the place where you find all information regarding your group project, and also the place to work on your group project. You will submit a copy of this file in the end.\n",
    "\n",
    "## Project description\n",
    "\n",
    "You are working in groups of 3-4 people. Each group will get assigned, at random, a dataset and a method that was discussed during the lecture. The datasets are coming from Earth System Sciences (Atmosphere and Climate), and are both taken from real-world research problems. Your task is to use the two methods you were assigned (one linear and one nonlinear statistical learning method) to fit and predict from the dataset you have been given. For the prediction, you will be given a part of the dataset consisting only of predictors but with target values omitted. For comparing your methods, you will also fit a multiple linear regression model (without any regularisation) to the dataset.\n",
    "\n",
    "The methods you have been assigned may or may not be suitable one for the dataset. However, the final performance of your code, that is the precision of your prediction, is not important. The key goal is to show that \n",
    "\n",
    "1. you understand the theoretical background of what a specific method is doing or attempts to do;\n",
    "2. you are aware of the strengths and limitations of a given method applied to a concrete atmospheric science problem;\n",
    "3. you are able to correctly apply the method in a training/testing context (e.g., cross-validation, hyperparameter selection, etc.);\n",
    "4. you are able to interpret the results of your method application to the atmospheric science problem.\n",
    "\n",
    "Below we have already constructed a framework that helps you through data reading and preparation, gives you space for model fitting and prediction and in the end asks you the questions you need to work on. So you just need to work along the framework and make sure you carefully answer each question, and then you can hand in!\n",
    "\n",
    "## Method and Data\n",
    "\n",
    "The pool of methods consists of\n",
    "\n",
    "| Method | R packages | Function/Help |\n",
    "| :- | :- | :- |\n",
    "| Backward subset selection | `leaps` | `?regsubsets` |\n",
    "| Principal component regression | `pls` | `?pcr` |\n",
    "| Ridge Regression | `glmnet` | `?glmnet` |\n",
    "| Lasso Regression | `glmnet` | `?glmnet` |\n",
    "| Multivariate adaptive regression splines | `earth` | `?earth` |\n",
    "| Random Forest | `randomForest` | `?randomForest` |\n",
    "| Boosted Trees | `gbm` | `?gbm` |\n",
    "\n",
    "NB: \n",
    "- You will be working with one linear and one non-parametric method from the method pool above. Please find on Moodle which of the methods is assigned to you.\n",
    "- You can follow the coding style from the exercises to implement your method. Use the help function (e.g. `?regsubsets`) to familiarize yourself with your methods and how to implement them.\n",
    "- In some cases, you will have to reduce the number of predictors to make it work with resource-demanding methods. \n",
    "\n",
    "\n",
    "And this is the dataset you'll be working with:\n",
    "\n",
    "### Statistical postprocessing of medium-range weather forecasts\n",
    "\n",
    "For this project, we will use the EUPPBench dataset (EUMETNET postprocessing benchmark, Demayer et al. 2023)$^1$. This dataset has been designed to facilitate the comparison of postprocessing techniques. Here 'postprocessing' refers to statistical methods that make use of past numerical weather predictions and observations to correct NWP forecast errors and biases. As such, they represent an important component of operational weather forecasting and are also commonly known as MOS (model output statistics). \n",
    "\n",
    "The EUPPBench dataset covers central Europe and we will be focusing on German data only. These data include both forecasts and observations, and they're already paired together, so it's ready for analysis. \n",
    "\n",
    "The forecast data were produced by the Integrated Forecasting System (IFS) of ECMWF for the year 2017. The regular forecast runs were initialized daily at midnight UTC and provided in 6-hour increments, up to 5 days ahead. Additionally, reforecasts were produced twice a week for the 20 previous years. Originally these forecasts were available as ensembles, but here we have included only their control runs to produce a deterministic forecasting scenario.\n",
    "\n",
    "The dataset contains weather observations from 49 stations that were provided by German weather service DWD. These observations span 22 years, from 1997 to 2017, so they can be compared with the forecasts and reforecasts in the dataset. For each of these stations, the EUPPBench dataset contains observations and weather forecasts for the closest grid point.\n",
    "\n",
    "The goal is to develop a statistical model for postprocessing temperature forecasts at these points. Following the traditional MOS approach, the prediction is based on the correlation between the NWP forecasts used as predictors and the colocated observed predictand. Mathematically, the forecast predictand at spatial location $s$ and some future time $t$ can be modelled as a function of a vector of NWP predictor variables $\\boldsymbol{x}_{s,t}$, such that\n",
    "\n",
    "$\\hat{y}_{s,t}=f(\\boldsymbol{x}_{s,t}).$\n",
    "\n",
    "Note that in the MOS approach, the time lag is carried by the NWP forecast and not by $f$. You will train such a model using the available NWP reforecasts (1997 - 2016), while testing over the forecast period (2017) and applying your model to the year 2018 where you do not know the true values (prediction challenge). **For this excercise, we will focus on predicting 2-metre air temperatures and we fix the forecast lead time at the maximum of 120h (5days) throughout the exercise (leadtime index 20 in data below), that is, all our forecasts and modelled should be fitted only for the 120h lead time.**\n",
    "\n",
    "For a successful application, you will need to find the right predictors and parameters for the machine learning model $f$ (the exact method is specified for each project). Select and argue for an approach that helps you to ensure that the chosen model parameters do not over-fit the training data.\n",
    "\n",
    "\n",
    "$^1$ Demaeyer, J., Bhend, J., Lerch, S., Primo, C., Van Schaeybroeck, B., Atencia, A., Ben Bouallègue, Z., Chen, J., Dabernig, M., Evans, G., Faganeli Pucer, J., Hooper, B., Horat, N., Jobst, D., Merše, J., Mlakar, P., Möller, A., Mestre, O., Taillardat, M., and Vannitsem, S.: The EUPPBench postprocessing benchmark dataset v1.0, Earth Syst. Sci. Data, 15, 2635–2653, https://doi.org/10.5194/essd-15-2635-2023, 2023. \n",
    "\n",
    "## Help\n",
    "\n",
    "Please use our moodle forum if you need help. For help on the specific methods or implementation choices, check the specific exercises (all methods have been part of the exercises), or use the R help (e.g., `?randomForest`).\n",
    "\n",
    "## IMPORTANT: A note on parallel working on a shared resource\n",
    "\n",
    "Please note that you will have to find a strategy to work on a shared resource. Each of you can follow the advice on Moodle and copy the group project folder in your personal directory. In this case, only the owner can access the data and notebook. \n",
    "You can, however, use UNIX commands to give everyone access. The command is \"chmod -R 777 group_project_folder/\". In this case, all of your group members can work in one member's folder, however it is important that **you don't work on it at the same time, and that you make regular backup copies**. Make sure to talk to each other before opening the shared notebook in your hub. Disregarding this advice might lead to loss of data!\n",
    "\n",
    "All groups are sharing the same server resources. Please be considerate and don't do very expensive analysis. It is ok to use a less precise, less expensive model in your final solution. It is what scientists do all the time. If you need to do that, make sure to discuss this decisions in the evaluation section.\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "Daniele Nerini has set up the original version of this student project, and his work is greatfully acknowledged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example code: local MOS\n",
    "\n",
    "To get you started, below you will find the code that loads and preprocesses the data, fits a simple linear regression model on the 20 years of reforecasts, and finally computes the overall performance on the forecast set for the years 2017; and apply your model to the year 2018 as an unseen test year (prediction challenge). For this, we will implement a local MOS, that is, we will fit a separate model for each station and lead time. \n",
    "\n",
    "The local strategy allows to capture spatial variability among stations as well as the dependency of NWP errors with time, but the obvious drawback is that we will be able to make predictions only at those locations that were available for training. Furthermore, note that the local approach might or might not be ideal for more sophisticated statistical learning approaches. As you experiment with more complex machine learning methods, we recommend that you think on different strategies. For a good discussion on local vs. global modelling approaches, see Rasp and Lerch (2018) $^2$.\n",
    "\n",
    "The example codes in this notebook are adapted from Demayer et al. (2023) and it only shows how to fit a local MOS for one station and lead time (it will be your first task to extend it to all stations and lead times).\n",
    "\n",
    "$^2$ Rasp, S., and S. Lerch, 2018: Neural Networks for Postprocessing Ensemble Weather Forecasts. Mon. Wea. Rev., 146, 3885–3900, https://doi.org/10.1175/MWR-D-18-0187.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(fields): there is no package called ‘fields’\n",
     "output_type": "error",
     "traceback": [
      "Error in library(fields): there is no package called ‘fields’\nTraceback:\n",
      "1. library(fields)"
     ]
    }
   ],
   "source": [
    "library(fields)\n",
    "library(maps)\n",
    "library(zoo)\n",
    "getwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data and do some basic plotting of the observed 2-metre temperature and the corresponding NWP forecast. Note that we will also refer to the latter as DMO (direct model output) to distinguish it from the postprocessed forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load RDS files\n",
    "fcs.test <- readRDS(\"data/ESSD_benchmark_test_data_forecasts.rds\")\n",
    "fcs.train <- readRDS(\"data/ESSD_benchmark_training_data_forecasts.rds\")\n",
    "obs.train <- readRDS(\"data/ESSD_benchmark_training_data_observations.rds\")\n",
    "obs.test <- readRDS(\"data/ESSD_benchmark_test_data_observations_4students.rds\")\n",
    "\n",
    "## inspect data structure\n",
    "# str(fcs.test) ## you can do the same for the other variables\n",
    "# str(obs.test)\n",
    "str(fcs.train)\n",
    "# str(obs.train)\n",
    "\n",
    "str(obs.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these four datasets contains various weather variables across different times and locations, along with metadata that provides context about the data.\n",
    "\n",
    "For example, the object `fcs.test` is a **List** with **5 main items** in it. Here's what each contains:\n",
    "\n",
    "1. **`data`**:\n",
    "   - This is a sub-list with **12 items**.\n",
    "   - Each item represents a different kind of weather-related data. They are three-dimensional numeric arrays with dimensions `[1:20, 1:730, 1:49]`, representing different lead times, forecast reference times, and stations, respectively.\n",
    "   - Examples of data types:\n",
    "     - `t2m`: *2 m air temperature*\n",
    "     - `tp6`: *Total precipitation accumulated over the past 6 hours*\n",
    "     - `sshf6`: *Surface sensible heat flux averaged over the past 6 hours*\n",
    "     - ... and more.\n",
    "\n",
    "2. **`latlon`**:\n",
    "   - A **data frame** (akin to a table) with **49 rows** and **4 columns**.\n",
    "   - Describes various stations or locations with:\n",
    "     - `station.id`: *Unique identifier for the station*\n",
    "     - `altitude`: *Height above sea level*\n",
    "     - `lon`: *Longitude*\n",
    "     - `lat`: *Latitude*\n",
    "\n",
    "3. **`time`**:\n",
    "   - Contains **730 time stamps** in POSIXct format.\n",
    "   - Start from \"2017-01-01T00\" with daily intervals, they represent the forecast initialization times.\n",
    "\n",
    "4. **`leadtime`**:\n",
    "   - Numeric array of **20 items**.\n",
    "   - Shows how many hours ahead each forecast is. (e.g., 6 hours ahead, 12 hours ahead, etc.)\n",
    "\n",
    "5. **`attrs`**:\n",
    "   - A sub-list with **16 items** providing metadata or attributes about the data.\n",
    "   - Acts like a glossary for the data.\n",
    "   - Examples:\n",
    "     - `t2m`: Represents *\"2 m air temperature\"* and has units in *Kelvin (K)*.\n",
    "     - `tp6`: Stands for *\"Total precipitation\"* and its units are *meters (m)*.\n",
    "     - ... and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Plot some of the test data\n",
    "# For the test data, you will see that the year 2018 in obs.test$data$t2m only contains NA's \n",
    "# -> this is your prediction challenge!\n",
    "\n",
    "## setup multi panel plot\n",
    "ll <- cbind(rep(1,2),2:3)\n",
    "ll <- rbind(rep(1,2), rep(1,2), rep(2,2))\n",
    "layout(ll)\n",
    "\n",
    "plot.new()\n",
    "plot.window(xlim=c(3,15),ylim=c(45,55))\n",
    "map(\"world\",add=TRUE,interior=TRUE)\n",
    "points(lat~lon,data=obs.test$latlon,cex=4,pch=21,col=\"blue\",bg=\"white\")\n",
    "title(main=\"Location of stations\")\n",
    "box()\n",
    "\n",
    "## select one station on the map\n",
    "sel.station <- 49 ## you can plot another station\n",
    "sel.leadtime <- 20 ## you can plot another leadtime \n",
    "points(lat~lon,data=obs.test$latlon[sel.station,],pch=1,cex=4,col=\"red\")\n",
    "\n",
    "## plot time series\n",
    "with(obs.test,plot(time,data$t2m[sel.leadtime,,sel.station],,t=\"l\",col=\"red\",main=\"2-metre air temperature at station\",\n",
    "                         ylab=\"K\"))\n",
    "with(fcs.test,lines(time,data$t2m[sel.leadtime,,sel.station],t=\"l\",col=\"blue\",\n",
    "                         ylab=\"k\"))\n",
    "\n",
    "legend(\"topright\", legend=c(\"Observed\", \"Forecasted\"), col=c(\"red\", \"blue\"), lty=c(1,2), cex=0.8)\n",
    "\n",
    "cor(obs.test$data$t2m[sel.leadtime,1:365,sel.station], fcs.test$data$t2m[sel.leadtime,1:365,sel.station], use = \"complete.obs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to reshape and recombine the data so that it can be ingested by the statistical model. Once the code executed, you will end up with data in a tabular manner (rows: datapoints, columns: variables = features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "## -- 1 -- Combine test data into one table\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "### As said, we will build individual models for each station and lead time, so let's\n",
    "### first pick one of each\n",
    "this_station <- 460  # station id\n",
    "this_leadtime <- 120  # hours\n",
    "\n",
    "idx.lt <- which(obs.test$leadtime == this_leadtime)\n",
    "idx.sta <- which(obs.test$latlon$station.id == this_station)\n",
    "obs <- obs.test$data$t2m[idx.lt,,idx.sta]\n",
    "time <- obs.test$time + this_leadtime * 3600   # leadtime is added to real time\n",
    "obs <- cbind(obs.test$time, this_leadtime, this_station, obs) # now obs at leadtime lt are combined with true time\n",
    "obs <- zoo(obs, time)\n",
    "colnames(obs) <- c('init', 'lt', 'stat', 'obs')\n",
    "\n",
    "idx.lt <- which(fcs.test$leadtime == this_leadtime)\n",
    "idx.sta <- which(fcs.test$latlon$station.id == this_station)\n",
    "dmo <- fcs.test$data$t2m[idx.lt,,idx.sta]\n",
    "\n",
    "test <- cbind(dmo)  # hint: you can add more predictors here\n",
    "# the following are possible (+ any transformations/interactions): \n",
    "# tp6 sshf6 slhf6 ssr6 str6 cp6 mx2t6 mn2t6 ssrd6 strd6 p10fg6\n",
    "\n",
    "time <- fcs.test$time + this_leadtime * 3600\n",
    "test <- zoo(test, time)\n",
    "test <- merge(obs, test)\n",
    "\n",
    "## inspect\n",
    "str(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "## -- 2 -- Combine train data into one table\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "trai.all <- NULL\n",
    "for(year in fcs.train$year){\n",
    "    \n",
    "    idx.lt <- which(obs.train$leadtime == this_leadtime)\n",
    "    idx.year <- which(obs.train$year == year)\n",
    "    idx.sta <- which(obs.train$latlon$station.id == this_station)\n",
    "\n",
    "    obs <- obs.train$data$t2m[idx.lt,idx.year,,idx.sta]\n",
    "    year.dummy <- as.POSIXct(paste0(2017 - 20 + year,'-01-02'))\n",
    "    time <- year.dummy + obs.train$time * 3600 * 24 + this_leadtime * 3600\n",
    "    fctime_obs_trai <- year.dummy + obs.train$time * 3600 * 24\n",
    "    obs <- cbind(fctime_obs_trai, this_leadtime, this_station, obs)\n",
    "    obs <- zoo(obs, time)\n",
    "    colnames(obs) <- c('init', 'lt', 'stat', 'obs')\n",
    "    \n",
    "    idx.lt <- which(fcs.train$leadtime == this_leadtime)\n",
    "    idx.year <- which(fcs.train$year == year)\n",
    "    idx.sta <- which(fcs.train$latlon$station.id == this_station)\n",
    "    dmo <- fcs.train$data$t2m[idx.lt,idx.year,,idx.sta]\n",
    "    trai <- cbind(dmo)  # hint: you can add more predictors here\n",
    "    time <- year.dummy + fcs.train$time * 3600 * 24 + this_leadtime * 3600\n",
    "    \n",
    "    trai <- zoo(trai, time)\n",
    "    trai <- merge(obs, trai)\n",
    "    \n",
    "    trai.all <- rbind(trai.all, trai)\n",
    "}\n",
    "\n",
    "trai <- na.omit(trai.all)\n",
    "### Using only data for trainig before 2017-01-01\n",
    "trai <- trai[which(index(trai) < as.POSIXct('2017-01-01')),]\n",
    "\n",
    "## inspect\n",
    "head(trai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we only extracted a sinlge predictor, namely the direct model output (DMO) for 2-metre air temperature. However, intuitively we would expect forecast errors to be affected by seasonality. To capture such a cyclical pattern in the data, we define two new predictors based on the day of the year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "### Convert K to °C (run only once!):\n",
    "trai$obs <- trai$obs - 273.15\n",
    "test$obs <- test$obs - 273.15\n",
    "trai$dmo <- trai$dmo - 273.15\n",
    "test$dmo <- test$dmo - 273.15\n",
    "\n",
    "\n",
    "### Adding sine and cosine for day of the year to capture seasonality\n",
    "\n",
    "## Decomposing the day of the year into sine and cosine components avoids the\n",
    "## discontinuity at the end of the year, which is particularly problematic with linear models.\n",
    "\n",
    "\n",
    "## train set\n",
    "yday <- as.POSIXlt(index(trai))$yday\n",
    "trai$sin.doy <- sin(2 * pi * yday / 365)\n",
    "trai$cos.doy <- cos(2 * pi * yday / 365)\n",
    "\n",
    "## test set\n",
    "yday <- as.POSIXlt(index(test))$yday\n",
    "test$sin.doy <- sin(2 * pi * yday / 365)\n",
    "test$cos.doy <- cos(2 * pi * yday / 365)\n",
    "\n",
    "plot(test$obs)\n",
    "lines(test$dmo, col = \"red\")\n",
    "\n",
    "## add more predictors here:\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "## -- 3 -- fit a simple linear regression model\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "fit.lm <- lm(obs ~ dmo + sin.doy + cos.doy, data=trai)\n",
    "\n",
    "## inspect\n",
    "fit.lm\n",
    "\n",
    "# evaluate your (more complex) model here, e.g. cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for test dataset for the years 2017 and 2018\n",
    "Finally, we use our trained model to make a prediction for the unseen test year 2018. We do it here illustratively for one station and the simple linear model; and your task is to make this prediction for all stations and for your assigned linear and non-parametric model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "## -- 4 -- Predict test year 2017 and 2018\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# you have observations to test for year 2017, but not for year 2018\n",
    "# str(test$dmo)\n",
    "\n",
    "my.pred = matrix(data = NA, nrow = 730, ncol = 49)  # prediction matrix with dimensions 730 days x 49 stations, similar to obs.test$data$t2m\n",
    "my.pred[,idx.sta] <- predict(fit.lm, newdata = test)\n",
    "str(my.pred)\n",
    "\n",
    "# plot prediction for one station (must be extended to 49 stations below...):\n",
    "dates <- as.Date(rownames(data.frame(test)))\n",
    "plot(dates, my.pred[,idx.sta], type='l', col = \"red\")\n",
    "lines(dates, test$obs)\n",
    "\n",
    "## further down you have to fill your my.pred with predictions for all 49 stations.\n",
    "\n",
    "# save my simple prediction:\n",
    "save(my.pred, file = \"my.OLS.MOS_group_X.rds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "## -- 5 -- Evaluate the performance compared to baseline\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "##  mean squared error\n",
    "mse.dmo = mean((test$obs - test$dmo)^2,na.rm=TRUE)\n",
    "mse.mos = mean((test$obs - my.pred[,idx.sta])^2,na.rm=TRUE)\n",
    "1 - mse.mos / mse.dmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expressed the overall performance (for this station and lead time) in terms of *skill score*, that is, the relative improvement compared to a baseline, which in our case is represented by the DMO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now it's your turn!\n",
    "\n",
    "Now it's your turn! Define the train and the test tables and fit the model to all stations and lead times. Evaluate the quality in terms of overall performance, but also stratify by stations and lead times. Remember to express the errors relatively to the raw NWP predictions.\n",
    "\n",
    "Above we did some feature engineering, i.e. added some features to the table that we think might be valuable for the prediction. However, you can choose how many features (one, some or all) for your model as you like. We suggest you play around a bit with it to understand what your model is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "### Loop over stations\n",
    "for(st in fcs.test$latlon$station.id){\n",
    "  print(paste0('Forecast at Station: ', st, ' (', which(fcs.test$latlon$station.id == st), ' from ', length(fcs.test$latlon$station.id), ')'))\n",
    "  \n",
    "    ## select fixed lead time of lt=120h    \n",
    "    \n",
    "    ## prepare data\n",
    "\n",
    "    ## fit model\n",
    "\n",
    "    ## predict\n",
    "\n",
    "    ## evaluate\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 4.2.2",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
